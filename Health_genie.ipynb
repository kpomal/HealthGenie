{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Health_genie",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpomal/HealthGenie/blob/main/Health_genie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-05T15:22:52.119732Z",
          "iopub.execute_input": "2025-04-05T15:22:52.120129Z",
          "iopub.status.idle": "2025-04-05T15:22:53.331791Z",
          "shell.execute_reply.started": "2025-04-05T15:22:52.120091Z",
          "shell.execute_reply": "2025-04-05T15:22:53.330821Z"
        },
        "id": "hVYePZ3eFuml"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio langchain langchain_google_genai"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-05T15:25:15.650952Z",
          "iopub.execute_input": "2025-04-05T15:25:15.651376Z",
          "iopub.status.idle": "2025-04-05T15:25:31.847245Z",
          "shell.execute_reply.started": "2025-04-05T15:25:15.651344Z",
          "shell.execute_reply": "2025-04-05T15:25:31.845951Z"
        },
        "id": "T1jhCL9DFumo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "import uuid\n",
        "\n",
        "# Directly set your Gemini API key here\n",
        "gemini_api_key = \"Your API Key\"  # Replace with your actual API key\n",
        "\n",
        "# Initialize the AI model with the chosen model\n",
        "llm = GoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.3, api_key=gemini_api_key)\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model for image classification\n",
        "image_model = tf.keras.applications.MobileNetV2(weights='imagenet')\n",
        "\n",
        "# Function to classify image as \"healthy\" or \"unhealthy\"\n",
        "def classify_image(image_file):\n",
        "    # Convert the uploaded PIL image to a numpy array\n",
        "    img_array = np.array(image_file)\n",
        "\n",
        "    # Resize the image to the size required by MobileNetV2 (224x224)\n",
        "    img_array = tf.image.resize(img_array, (224, 224))\n",
        "\n",
        "    # Convert the image to NumPy array if it's a TensorFlow tensor and ensure it is writable\n",
        "    img_array = img_array.numpy() if isinstance(img_array, tf.Tensor) else img_array\n",
        "    img_array = img_array.copy()  # Ensure it's writable\n",
        "\n",
        "    # Expand dimensions to match model's expected input format (batch size, height, width, channels)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Preprocess the image for MobileNetV2\n",
        "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
        "\n",
        "    # Make prediction using the model\n",
        "    predictions = image_model.predict(img_array)\n",
        "\n",
        "    # Decode the top 3 predictions\n",
        "    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=3)[0]\n",
        "\n",
        "    # Log the decoded predictions (for debugging purposes)\n",
        "    print(\"Decoded Predictions:\", decoded_predictions)\n",
        "\n",
        "    # Classify as \"healthy\" or \"unhealthy\" based on the prediction\n",
        "    healthy_keywords = ['apple', 'banana', 'carrot', 'broccoli', 'salad', 'strawberry', 'spinach', 'avocado', 'tomato', 'cucumber']\n",
        "    unhealthy_keywords = ['pizza', 'burger', 'fries', 'soda', 'cake', 'chips', 'candy', 'donut', 'cookie']\n",
        "\n",
        "    # Check if the label matches any healthy or unhealthy keywords\n",
        "    for _, label, _ in decoded_predictions:\n",
        "        if any(healthy_keyword in label.lower() for healthy_keyword in healthy_keywords):\n",
        "            return \"Healthy food!\"\n",
        "        elif any(unhealthy_keyword in label.lower() for unhealthy_keyword in unhealthy_keywords):\n",
        "            return \"Unhealthy food!\"\n",
        "\n",
        "    # If no match is found, return a default message\n",
        "    return \"Cannot classify food. Please try another image.\"\n",
        "\n",
        "# Function to call the Gemini API for health advice\n",
        "def call_gemini_api(query):\n",
        "    # Few-shot examples for the model to generate health advice\n",
        "    few_shot_examples = [\n",
        "        \"Q: What are the benefits of drinking water?\\nA: - Hydration\\n   - Improves skin health\\n   - Aids digestion\\n   - Regulates body temperature\",\n",
        "        \"Q: How can I improve my sleep quality?\\nA: - Establish a regular sleep schedule\\n   - Create a relaxing bedtime routine\\n   - Limit screen time before bed\\n   - Keep your bedroom cool and dark\",\n",
        "        \"Q: What are some healthy snacks?\\nA: - Fresh fruits (e.g., apples, bananas)\\n   - Nuts and seeds\\n   - Yogurt\\n   - Vegetable sticks with hummus\"\n",
        "    ]\n",
        "\n",
        "    # Combine the few-shot examples with the user query to create the prompt\n",
        "    prompt = \"\\n\".join(few_shot_examples) + f\"\\nQ: {query}\\nA:\"\n",
        "\n",
        "    # Generate response from the AI model\n",
        "    response = llm.generate([prompt])  # Pass the prompt as a single string\n",
        "    response_text = response.generations[0][0].text.strip()\n",
        "\n",
        "    # Format the response into bullet points for better readability\n",
        "    formatted_response = \"\\n\".join([f\"- **{line.strip()}**\" for line in response_text.split(\"\\n\") if line.strip()])\n",
        "\n",
        "    # Generate a unique filename for the response\n",
        "    file_name = f\"response_{uuid.uuid4().hex}.txt\"\n",
        "\n",
        "    # Save the response to a text file for download\n",
        "    with open(file_name, \"w\") as f:\n",
        "        f.write(formatted_response)\n",
        "\n",
        "    return formatted_response, file_name  # Return the formatted response and the file path\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks() as iface:\n",
        "    gr.Markdown(\"# HealthGenie AI Assistant\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # Text-based AI Assistant for health queries\n",
        "            query_input = gr.Textbox(label=\"Ask HealthGenie anything:\", placeholder=\"Type your question here...\")\n",
        "            response_output = gr.Textbox(label=\"Response\", interactive=False)\n",
        "            download_file = gr.File(label=\"Download Response\")\n",
        "            query_input.submit(call_gemini_api, query_input, [response_output, download_file])\n",
        "\n",
        "        with gr.Column():\n",
        "            # Image classification section\n",
        "            image_input = gr.Image(type=\"numpy\", label=\"Upload an image of food\")\n",
        "            classify_button = gr.Button(\"Classify Image\")\n",
        "            output_label = gr.Textbox(label=\"Food Classification\", interactive=False)\n",
        "\n",
        "            # When the classify button is clicked, the image classification function is called\n",
        "            classify_button.click(classify_image, image_input, output_label)\n",
        "\n",
        "# Launch the Gradio app\n",
        "iface.launch(share=True)  # Enable sharing to generate a URL to interact with the interface\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-05T15:25:39.808052Z",
          "iopub.execute_input": "2025-04-05T15:25:39.808393Z",
          "iopub.status.idle": "2025-04-05T15:26:03.970582Z",
          "shell.execute_reply.started": "2025-04-05T15:25:39.808364Z",
          "shell.execute_reply": "2025-04-05T15:26:03.969504Z"
        },
        "id": "CM6lOE-3Fumo"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}